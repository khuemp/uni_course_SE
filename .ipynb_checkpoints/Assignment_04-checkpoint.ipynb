{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the python template for Assignment 04.  \n",
    "- You must use this template.  \n",
    "- You must not change any signatures of the methods, only edit the sections indicated with \"Write your code here.\"  \n",
    "- The return of every function has to be in the right format, otherwise this is a desk reject.  \n",
    "- Plagiarism leads to failing the assignment!  \n",
    "- We will terminate the script after 10 min, try to use efficient algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name():\n",
    "    # DONE: Write your code here. And change the return.\n",
    "    return \"Minh Khue Pham\"\n",
    "def get_matriculationnumber():\n",
    "    # DONE: Write your code here. And change the return.\n",
    "    return 2579036"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful information:\n",
    "\n",
    "The structure of a CART is a dict. Use the same names as shown in the example, using other names makes your format invalid and leads to a desk reject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart = { \"name\":\"X\", \"mean\":456, \"split_by_feature\": \"aes\", \"error_of_split\": 0.0,\n",
    "        \"successor_left\": { \"name\":\"XL\", \"mean\":1234, \"split_by_feature\": None, \"error_of_split\":None,\n",
    "                           \"successor_left\":None,\n",
    "                           \"successor_right\":None\n",
    "                          },\n",
    "        \"successor_right\":{ \"name\":\"XR\", \"mean\":258, \"split_by_feature\": None,\"error_of_split\":None,\n",
    "                           \"successor_left\":None,\n",
    "                           \"successor_right\":None\n",
    "                          }\n",
    "       }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names of the features must be used as defined in this list, using other names makes your format invalid and leads to a desk reject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"secompress\", \"encryption\", \"aes\", \"blowfish\", \"algorithm\", \"rar\", \"zip\", \"signature\",\n",
    "            \"timestamp\", \"segmentation\", \"onehundredmb\", \"onegb\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Create a CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your helper functions here, if needed\n",
    "def get_best_split(df):\n",
    "    # Calculate mean for whole dataframe\n",
    "    mean = 0\n",
    "    for index, row in df.iterrows():\n",
    "        mean += row[\"performance\"]\n",
    "    mean = mean / len(df)\n",
    "    \n",
    "    # Return None feature, mean and None error of split if all performaces equal mean\n",
    "    optimal = True\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"performance\"] != mean: # Not yet optimal subtree\n",
    "            optimal = False\n",
    "    if optimal:\n",
    "        return None, mean, None # No better split\n",
    "    \n",
    "    bestFeature, bestErrorOfSplit = None, float('inf')\n",
    "    # Iterate to chose best feature\n",
    "    # Get remaining features name\n",
    "    dfFeatureOnly = df.loc[:, ~df.columns.isin([\"Id\", \"performance\"])]\n",
    "    for f in dfFeatureOnly.columns:\n",
    "        numYes, numNo, sumPerformYes, sumPerformNo, sumSquaredError = 0, 0, 0, 0, 0\n",
    "        # Iterate to calculate sum and count number of configurations that (not) have feature f\n",
    "        for index, row in df.iterrows():\n",
    "            if row[f] == 1:\n",
    "                numYes += 1\n",
    "                sumPerformYes += row[\"performance\"]\n",
    "            else:\n",
    "                numNo += 1\n",
    "                sumPerformNo += row[\"performance\"]\n",
    "        # Move to next feature if all datas have same value on this feature  \n",
    "        if (numYes == 0) or (numNo == 0):\n",
    "            continue\n",
    "        # Calculate sum squared error\n",
    "        for index, row in df.iterrows():\n",
    "            if (row[f] == 1):\n",
    "                sumSquaredError += (row[\"performance\"] - sumPerformYes/numYes) ** 2\n",
    "            else:\n",
    "                sumSquaredError += (row[\"performance\"] - sumPerformNo/numNo) ** 2\n",
    "        # Update best feature and its error of split\n",
    "        if (sumSquaredError < bestErrorOfSplit) or ((sumSquaredError == bestErrorOfSplit) and (f == min(f, bestFeature))):\n",
    "            bestFeature = f\n",
    "            bestErrorOfSplit = sumSquaredError\n",
    "    return bestFeature, mean, bestErrorOfSplit\n",
    "\n",
    "def get_sub_tree(df, name):\n",
    "    bestFeature, mean, bestErrorOfSplit = get_best_split(df)\n",
    "    if bestFeature == None:\n",
    "        return { \"name\":name, \"mean\": mean, \"split_by_feature\": bestFeature, \"error_of_split\":bestErrorOfSplit,\n",
    "           \"successor_left\":None,\"successor_right\":None}\n",
    "    leftdf = df[df[bestFeature] == 1].loc[:, df.columns != bestFeature]\n",
    "    rightdf = df[df[bestFeature] == 0].loc[:, df.columns != bestFeature]\n",
    "    return { \"name\":name, \"mean\": mean, \"split_by_feature\": bestFeature, \"error_of_split\":bestErrorOfSplit,\n",
    "       \"successor_left\":get_sub_tree(leftdf, name + \"L\"),\"successor_right\":get_sub_tree(rightdf, name + \"R\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cart(sample_set_csv):\n",
    "    # The sample_set_csv is a file path to a csv data, this can be imported into a dataframe\n",
    "    df = pd.read_csv(sample_set_csv)\n",
    "    # DONE: Write your code here. And change the return.\n",
    "    return get_sub_tree(df, \"X\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2a: Highest influencing feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your helper functions here, if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_highest_influence_feature(cart):\n",
    "    # DONE: Write your code here. And change the return.\n",
    "    return cart.get(\"split_by_feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2b: Calculate the error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your helper functions here, if needed\n",
    "def get_sum_of_difference(cart, df):\n",
    "    sumDifference = 0\n",
    "    splitFeature = get_highest_influence_feature(cart)\n",
    "    if splitFeature == None:\n",
    "        for index, row in df.iterrows():\n",
    "            sumDifference += abs(row[\"performance\"] - cart.get(\"mean\"))\n",
    "        return sumDifference\n",
    "    leftdf = df[df[splitFeature] == 1]\n",
    "    rightdf = df[df[splitFeature] == 0]\n",
    "    leftCart = cart.get(\"successor_left\")\n",
    "    rightCart = cart.get(\"successor_right\")\n",
    "    return get_sum_of_difference(leftCart, leftdf) + get_sum_of_difference(rightCart, rightdf)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_rate(cart, sample_set_csv):\n",
    "    # The sample_set_csv is a file path to a csv data, this can be imported into a dataframe\n",
    "    df = pd.read_csv(sample_set_csv)\n",
    "    # DONE: Write your code here. And change the return.\n",
    "    return get_sum_of_difference(cart, df)/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2c: Generate optimal configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your helper functions here, if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_configuration(cart, partial_configuration):\n",
    "    # TODO: Write your code here. And change the return.\n",
    "    return {\"rar\", \"timestamp\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests:  \n",
    "In the following cells, we provide you some test cases (but not all possible test cases!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n"
     ]
    }
   ],
   "source": [
    "# Task 1\n",
    "\n",
    "test_cart = {'name': 'X', 'mean': 763.2, 'split_by_feature': 'segmentation', 'error_of_split': 6.0, \n",
    "             'successor_left': \n",
    "                 {'name': 'XL', 'mean': 772.0, 'split_by_feature': 'onegb', 'error_of_split': 0.0, \n",
    "                  'successor_left': \n",
    "                      {'name': 'XLL', 'mean': 770.0, 'split_by_feature': None, 'error_of_split': None, \n",
    "                       'successor_left': None, \n",
    "                       'successor_right': None\n",
    "                      }, \n",
    "                  'successor_right': \n",
    "                      {'name': 'XLR', 'mean': 773.0, 'split_by_feature': None, 'error_of_split': None, \n",
    "                       'successor_left': None, \n",
    "                       'successor_right': None\n",
    "                      }\n",
    "                 }, \n",
    "             'successor_right': \n",
    "                 {'name': 'XR', 'mean': 750.0, 'split_by_feature': None, 'error_of_split': None, \n",
    "                  'successor_left': None, \n",
    "                  'successor_right': None}\n",
    "            }\n",
    "\n",
    "\n",
    "if get_cart(\"Performance_01.csv\") == test_cart:\n",
    "    print(\"passed\")\n",
    "else:\n",
    "    print(\"failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n"
     ]
    }
   ],
   "source": [
    "# Task 2b\n",
    "if get_error_rate(test_cart, \"Performance_02b.csv\") == 5:\n",
    "    print(\"passed\")\n",
    "else:\n",
    "    print(\"failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed\n"
     ]
    }
   ],
   "source": [
    "# Task 2c\n",
    "test_cart_v2 = {'name': 'X', 'mean': 763.2, 'split_by_feature': 'zip', 'error_of_split': 0.0, \n",
    "                 'successor_left': {'name': 'XL', 'mean': 772.0, 'split_by_feature': None, 'error_of_split': None, \n",
    "                                    'successor_left': None, \n",
    "                                    'successor_right': None}, \n",
    "                 'successor_right': {'name': 'XR', 'mean': 750.0, 'split_by_feature': None, 'error_of_split': None, \n",
    "                                     'successor_left': None, \n",
    "                                     'successor_right': None}\n",
    "                }\n",
    "\n",
    "optimal_config = get_optimal_configuration(test_cart_v2, {\"secompress\", \"encryption\", \"aes\", \"algorithm\", \"signature\",\n",
    "                                                        \"timestamp\", \"segmentation\", \"onehundredmb\"})\n",
    "reference = {'aes', 'algorithm', 'encryption', 'onehundredmb', 'rar', 'secompress', 'segmentation', 'signature',\n",
    "            'timestamp'}\n",
    "\n",
    "if optimal_config == reference:\n",
    "    print(\"passed\")\n",
    "else:\n",
    "    print(\"failed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
